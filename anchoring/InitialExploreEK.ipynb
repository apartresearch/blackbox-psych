{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Anchoring\n",
    "This notebook is for doing initial explorations of how to investigate anchoring / in general conduct psychological experiments on large language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename: str) -> dict:\n",
    "    with open(filename) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "        \n",
    "def get_api_key(config, keyname: str = \"goose_api\") -> str:\n",
    "    \"\"\"\n",
    "    Gets the API key from the config file.\n",
    "    \"\"\"\n",
    "    return read_json(config)[keyname]\n",
    "    \n",
    "def authenticate_goose(config) -> None:\n",
    "    \"\"\"\n",
    "    Authenticates with the goose API.\n",
    "    \"\"\"\n",
    "    api_key = get_api_key(config, keyname=\"goose_api\")\n",
    "    openai.api_key = api_key\n",
    "    openai.api_base = \"https://api.goose.ai/v1\"\n",
    "\n",
    "\n",
    "def authenticate_openai(config) -> None:\n",
    "    \"\"\"\n",
    "    Authenticates with the goose API.\n",
    "    \"\"\"\n",
    "    api_key = get_api_key(config, keyname=\"openai_api\")\n",
    "    openai.api_key = api_key\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "\n",
    "def generate_prompt(\n",
    "    prompt: str, model_name: str = \"gpt-neo-125m\", max_tokens: int = 75, temperature=0.9\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a prompt using a model from EleutherAI.\n",
    "    \"\"\"\n",
    "    return openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        engine=model_name,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )[\"choices\"][0][\"text\"]\n",
    "\n",
    "def find_first_num(s: str):\n",
    "    \"\"\"\n",
    "    Finds first integer or floating point in string\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", re.sub(r'[,]','',s))[0]\n",
    "    except IndexError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              engine  max_tokens  temperature  \\\n",
      "0           gpt-j-6b          30          0.7   \n",
      "1        gpt-neo-20b          30          0.7   \n",
      "2        fairseq-13b          30          0.7   \n",
      "3           gpt-j-6b          30          0.7   \n",
      "4        gpt-neo-20b          30          0.7   \n",
      "..               ...         ...          ...   \n",
      "70      text-ada-001          30          0.7   \n",
      "71  text-davinci-002          30          0.7   \n",
      "72      text-ada-001          30          0.7   \n",
      "73  text-davinci-002          30          0.7   \n",
      "74      text-ada-001          30          0.7   \n",
      "\n",
      "                                               prompt  stream  \\\n",
      "0   Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "1   Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "2   Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "3   Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "4   Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "..                                                ...     ...   \n",
      "70  Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "71  Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "72  Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "73  Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "74  Q: Height of Taj Mahal (in feet).\\nA: 239.5.\\n...   False   \n",
      "\n",
      "                                             question  n  \\\n",
      "0              Length of Mississippi River (in miles)  1   \n",
      "1              Length of Mississippi River (in miles)  1   \n",
      "2              Length of Mississippi River (in miles)  1   \n",
      "3                   Height of Mount Everest (in feet)  1   \n",
      "4                   Height of Mount Everest (in feet)  1   \n",
      "..                                                ... ..   \n",
      "70                     Number of bars in Berkeley, CA  1   \n",
      "71  Number of state colleges and universities in C...  1   \n",
      "72  Number of state colleges and universities in C...  1   \n",
      "73                     Number of Lincoln's presidency  1   \n",
      "74                     Number of Lincoln's presidency  1   \n",
      "\n",
      "                                               answer  \n",
      "0    733.\\n\\n\\n3\\n The district court found that \"...  \n",
      "1    2,321.\\n\\n<|endoftext|>Q:\\n\\nHow to extract a...  \n",
      "2    31,576.\\nEncyclopedia Britannica.\\n\\nMaurice ...  \n",
      "3    8848.\\n\\nQ: Height of Mount Everest (meters)....  \n",
      "4    8,848.86.\\n\\nQ: How long is the Golden Gate B...  \n",
      "..                                                ...  \n",
      "70    \\n\\nThe number of bars on the Taj Mahal is 100.  \n",
      "71                                               112.  \n",
      "72  \\n\\nThere are currently 18 California state co...  \n",
      "73                                                 4.  \n",
      "74       \\n\\nThe number of Lincoln's presidency is 9.  \n",
      "\n",
      "[75 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Length of Mississippi River (in miles)\",\n",
    "    \"Height of Mount Everest (in feet)\",\n",
    "    \"Amount of meat eaten per year by average American (in pounds)\",\n",
    "    \"Distance from San Francisco to New York City (in miles)\",\n",
    "    \"Height of tallest redwood (in feet)\",\n",
    "    \"Number of United Nations members\",\n",
    "    \"Number of female professors at the University of California, Berkeley\",\n",
    "    \"Population of Chicago (in millions)\",\n",
    "    \"Year telephone was invented\",\n",
    "    \"Average number of babies born per day in the United States\",\n",
    "    \"Maximum speed of house cat (in miles per hour)\",\n",
    "    \"Amount of gas used per month by average American (in gallons)\",\n",
    "    \"Number of bars in Berkeley, CA\",\n",
    "    \"Number of state colleges and universities in California\",\n",
    "    \"Number of Lincoln's presidency\"\n",
    "]\n",
    "\n",
    "context = \"\"\"Q: Height of Taj Mahal (in feet).\n",
    "A: 239.5.\n",
    "\n",
    "Q: \"\"\"\n",
    "\n",
    "post_script = \"\"\".\n",
    "A:\"\"\"\n",
    "\n",
    "estimates_calibration = []\n",
    "repetitions = 1\n",
    "authenticate_goose(\"../config.json\")\n",
    "engines = [\"gpt-j-6b\", \"gpt-neo-20b\", \"fairseq-13b\"]\n",
    "\n",
    "for q in questions:\n",
    "    prompt = context + q + post_script\n",
    "    for engine in engines:\n",
    "        row = {\"engine\": engine, \"max_tokens\": 30, \"temperature\": 0.7,\n",
    "            \"prompt\": prompt, \"stream\": False, \"question\": q, \"n\": repetitions}\n",
    "\n",
    "        completion = openai.Completion.create(**row)\n",
    "        completion_text = \"\"\n",
    "        row[\"question\"] = q\n",
    "        for c in completion[\"choices\"]:\n",
    "            completion_text = dict(c)[\"text\"]\n",
    "            row[\"answer\"] = completion_text\n",
    "\n",
    "            estimates_calibration.append(row)\n",
    "\n",
    "authenticate_openai(\"../config.json\")\n",
    "engines = [\"text-davinci-002\", \"text-ada-001\"]\n",
    "\n",
    "for q in questions:\n",
    "    prompt = context + q + post_script\n",
    "    for engine in engines:\n",
    "        row = {\"engine\": engine, \"max_tokens\": 30, \"temperature\": 0.7,\n",
    "            \"prompt\": prompt, \"stream\": False, \"n\": repetitions}\n",
    "\n",
    "        completion = openai.Completion.create(**row)\n",
    "        completion_text = \"\"\n",
    "        row[\"question\"] = q\n",
    "        for c in completion[\"choices\"]:\n",
    "            completion_text = dict(c)[\"text\"]\n",
    "            row[\"answer\"] = completion_text\n",
    "            estimates_calibration.append(row)\n",
    "\n",
    "df = pd.DataFrame.from_records(estimates_calibration)\n",
    "df.to_csv(\"output/estimates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-99267.0, -9267.0, -267.0, 633.0, 683.0, 723.0, 728.0, 731.0, 733.0, 735.0, 738.0, 743.0, 783.0, 833.0, 1733.0, 10733.0, 100733.0]\n",
      "[-91152.0, -1152.0, 7848.0, 8748.0, 8798.0, 8838.0, 8843.0, 8846.0, 8848.0, 8850.0, 8853.0, 8858.0, 8898.0, 8948.0, 9848.0, 18848.0, 108848.0]\n",
      "[-99999.0, -9999.0, -999.0, -99.0, -49.0, -9.0, -4.0, -1.0, 1.0, 3.0, 6.0, 11.0, 51.0, 101.0, 1001.0, 10001.0, 100001.0]\n",
      "[-99994.0, -9994.0, -994.0, -94.0, -44.0, -4.0, 1.0, 4.0, 6.0, 8.0, 11.0, 16.0, 56.0, 106.0, 1006.0, 10006.0, 100006.0]\n",
      "[-99988.0, -9988.0, -988.0, -88.0, -38.0, 2.0, 7.0, 10.0, 12.0, 14.0, 17.0, 22.0, 62.0, 112.0, 1012.0, 10012.0, 100012.0]\n",
      "[-99807.0, -9807.0, -807.0, 93.0, 143.0, 183.0, 188.0, 191.0, 193.0, 195.0, 198.0, 203.0, 243.0, 293.0, 1193.0, 10193.0, 100193.0]\n",
      "[-99996.0, -9996.0, -996.0, -96.0, -46.0, -6.0, -1.0, 2.0, 4.0, 6.0, 9.0, 14.0, 54.0, 104.0, 1004.0, 10004.0, 100004.0]\n",
      "[-99997.3, -9997.3, -997.3, -97.3, -47.3, -7.3, -2.3, 0.7000000000000002, 2.7, 4.7, 7.7, 12.7, 52.7, 102.7, 1002.7, 10002.7, 100002.7]\n",
      "[-98044.0, -8044.0, 956.0, 1856.0, 1906.0, 1946.0, 1951.0, 1954.0, 1956.0, 1958.0, 1961.0, 1966.0, 2006.0, 2056.0, 2956.0, 11956.0, 101956.0]\n",
      "[-99997.54, -9997.54, -997.54, -97.54, -47.54, -7.54, -2.54, 0.45999999999999996, 2.46, 4.46, 7.46, 12.46, 52.46, 102.46, 1002.46, 10002.46, 100002.46]\n",
      "[-99930.0, -9930.0, -930.0, -30.0, 20.0, 60.0, 65.0, 68.0, 70.0, 72.0, 75.0, 80.0, 120.0, 170.0, 1070.0, 10070.0, 100070.0]\n",
      "[-99999.0, -9999.0, -999.0, -99.0, -49.0, -9.0, -4.0, -1.0, 1.0, 3.0, 6.0, 11.0, 51.0, 101.0, 1001.0, 10001.0, 100001.0]\n",
      "[-99999.0, -9999.0, -999.0, -99.0, -49.0, -9.0, -4.0, -1.0, 1.0, 3.0, 6.0, 11.0, 51.0, 101.0, 1001.0, 10001.0, 100001.0]\n",
      "[-99967.0, -9967.0, -967.0, -67.0, -17.0, 23.0, 28.0, 31.0, 33.0, 35.0, 38.0, 43.0, 83.0, 133.0, 1033.0, 10033.0, 100033.0]\n",
      "[-99996.0, -9996.0, -996.0, -96.0, -46.0, -6.0, -1.0, 2.0, 4.0, 6.0, 9.0, 14.0, 54.0, 104.0, 1004.0, 10004.0, 100004.0]\n",
      "0                      2,045.0.\\n\\n Random number: -1546.6\n",
      "1                        2,140.0.\\n\\n Random number: -7.0.\n",
      "2                     3,918.5.\\nQ: The last four digits of\n",
      "3                     4,320.0.\\n\\n Random number : -83212.\n",
      "4                      5,110.0.\\n\\n Random number: -4981.0\n",
      "                               ...                        \n",
      "12745                  4.\\n\\n### **Caffeine Catechesis**\\n\n",
      "12746                12.\\nQ: Oldest city in the world.\\nA:\n",
      "12747     10.\\n\\n Random number: 101.\\nQ: The year the ...\n",
      "12748          12.\\n\\n Random number: 100005.0.\\nQ: Height\n",
      "12749            (Valued) 18.\\n\\n Random number: 100005.0.\n",
      "Name: answer, Length: 12750, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Log nums away from the base value\n",
    "log_nums = [-100000, -10000, -1000, -100, -50, -10, -5, -2, 0, 2, 5, 10, 50, 100, 1000, 10000, 100000]\n",
    "\n",
    "# Load default numbers\n",
    "estimates = pd.read_csv(\"output/estimates.csv\")\n",
    "estimates[\"answer_num\"] = [find_first_num(answer) for answer in estimates[\"answer\"]]\n",
    "\n",
    "# Set context\n",
    "context = \"\"\"Q: Height of Taj Mahal (in feet).\n",
    "A: 239.5.\n",
    "\n",
    "Random number: \"\"\"\n",
    "\n",
    "post_number = \"\"\".\n",
    "Q: \"\"\"\n",
    "\n",
    "post_script = \"\"\".\n",
    "A:\"\"\"\n",
    "\n",
    "experimental = []\n",
    "repetitions = 50\n",
    "\n",
    "# Set engines\n",
    "authenticate_goose(\"../config.json\")\n",
    "engines = [\"gpt-j-6b\"]\n",
    "\n",
    "# Run machine\n",
    "for q in questions:\n",
    "    test_numbers =  [float(estimates[estimates[\"question\"] == q].iloc[0][\"answer_num\"]) + num for num in log_nums]\n",
    "    print(test_numbers)\n",
    "    \n",
    "    for num in test_numbers:\n",
    "        prompt = context + str(num) + post_number + q + post_script\n",
    "        for engine in engines:\n",
    "            row = {\"engine\": engine, \"max_tokens\": 15, \"temperature\": 0.7,\n",
    "                \"prompt\": prompt, \"stream\": False, \"n\": repetitions}\n",
    "\n",
    "            completion = openai.Completion.create(**row)\n",
    "            completion_text = \"\"\n",
    "            row[\"question\"] = q\n",
    "            row[\"anchor\"] = num\n",
    "            row[\"calibration\"] = float(estimates[estimates[\"question\"] == q].iloc[0][\"answer_num\"])\n",
    "            row[\"anchor_diff\"] = num - row[\"calibration\"]\n",
    "            row[\"answer\"] = \"\"\n",
    "\n",
    "            for c in completion[\"choices\"]:\n",
    "                completion_text = c[\"text\"]\n",
    "                row |= {\"answer\": completion_text}\n",
    "                \n",
    "                experimental.append(row.copy())\n",
    "\n",
    "df = pd.DataFrame.from_records(experimental)\n",
    "df.to_csv(\"output/3_test.csv\")\n",
    "print(df[\"answer\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
